{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BUCC.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7xoDmlvIeuhK","executionInfo":{"status":"ok","timestamp":1654589898470,"user_tz":-120,"elapsed":26575,"user":{"displayName":"Everlyn Asiko Chimoto","userId":"04364481505979678301"}},"outputId":"e58b2196-72ff-4872-9a60-6c6d14c87e1d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir(\"/content/gdrive/Shareddrives/LASER_on_Luhya\")"],"metadata":{"id":"CLkI7ufneyU5","executionInfo":{"status":"ok","timestamp":1654589959452,"user_tz":-120,"elapsed":5,"user":{"displayName":"Everlyn Asiko Chimoto","userId":"04364481505979678301"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!python3 --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eSHYSpaYtq9i","executionInfo":{"status":"ok","timestamp":1654589905136,"user_tz":-120,"elapsed":522,"user":{"displayName":"Everlyn Asiko Chimoto","userId":"04364481505979678301"}},"outputId":"13e2fc82-c6fc-4b29-cf99-a988e42ddea0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.7.13\n"]}]},{"cell_type":"markdown","source":["# BUCC Task trial"],"metadata":{"id":"ObJqfFAL0zns"}},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jZDDj1kde_Xr","executionInfo":{"status":"ok","timestamp":1654589908634,"user_tz":-120,"elapsed":553,"user":{"displayName":"Everlyn Asiko Chimoto","userId":"04364481505979678301"}},"outputId":"8269c006-2366-40d5-ca75-92c3be86c030"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["BUCC.ipynb  LASER  Laser.ipynb\tLuhya.csv  requirements.txt  swahilisawa.csv\n"]}]},{"cell_type":"code","source":["! pip3 install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"XRgc4eAFfBnd","executionInfo":{"status":"ok","timestamp":1654589939428,"user_tz":-120,"elapsed":27799,"user":{"displayName":"Everlyn Asiko Chimoto","userId":"04364481505979678301"}},"outputId":"7a650298-3556-424e-f266-ad2437687a87"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting faiss-cpu\n","  Downloading faiss_cpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n","\u001b[K     |████████████████████████████████| 8.6 MB 26.2 MB/s \n","\u001b[?25hCollecting faiss-gpu\n","  Downloading faiss_gpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n","\u001b[K     |████████████████████████████████| 85.5 MB 113 kB/s \n","\u001b[?25hCollecting Cython==0.29.6\n","  Downloading Cython-0.29.6-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 55.8 MB/s \n","\u001b[?25hCollecting fastBPE\n","  Downloading fastBPE-0.1.0.tar.gz (35 kB)\n","Collecting fairseq==0.10.2\n","  Downloading fairseq-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 51.8 MB/s \n","\u001b[?25hCollecting transliterate\n","  Downloading transliterate-1.10.2-py2.py3-none-any.whl (45 kB)\n","\u001b[K     |████████████████████████████████| 45 kB 3.8 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 61.0 MB/s \n","\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2->-r requirements.txt (line 5)) (1.15.0)\n","Collecting dataclasses\n","  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2->-r requirements.txt (line 5)) (1.11.0+cu113)\n","Collecting hydra-core\n","  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 76.5 MB/s \n","\u001b[?25hCollecting sacrebleu>=1.4.12\n","  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n","\u001b[K     |████████████████████████████████| 92 kB 11.9 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2->-r requirements.txt (line 5)) (2019.12.20)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2->-r requirements.txt (line 5)) (4.64.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2->-r requirements.txt (line 5)) (1.21.6)\n","Collecting portalocker\n","  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==0.10.2->-r requirements.txt (line 5)) (0.8.9)\n","Requirement already satisfied: six>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from transliterate->-r requirements.txt (line 6)) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==0.10.2->-r requirements.txt (line 5)) (2.21)\n","Collecting omegaconf~=2.2\n","  Downloading omegaconf-2.2.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 9.7 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq==0.10.2->-r requirements.txt (line 5)) (21.3)\n","Collecting antlr4-python3-runtime==4.9.*\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 76.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq==0.10.2->-r requirements.txt (line 5)) (5.7.1)\n","Collecting PyYAML>=5.1.0\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 66.3 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core->fairseq==0.10.2->-r requirements.txt (line 5)) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hydra-core->fairseq==0.10.2->-r requirements.txt (line 5)) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq==0.10.2->-r requirements.txt (line 5)) (4.2.0)\n","Building wheels for collected packages: fastBPE, antlr4-python3-runtime\n","  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp37-cp37m-linux_x86_64.whl size=483895 sha256=e14b60715e1e224003216963cc9d6d938069586b08081f29518a513b8767a3e4\n","  Stored in directory: /root/.cache/pip/wheels/bd/d4/0e/0d317a65f77d3f8049fedd8a2ee0519164cf3e6bd77ef886f1\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=bee771583ec7c7ee1c58e40ba7b4f9471e0f75b8ad3e3364268f4623c98eb942\n","  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n","Successfully built fastBPE antlr4-python3-runtime\n","Installing collected packages: PyYAML, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, dataclasses, Cython, transliterate, sentencepiece, fastBPE, faiss-gpu, faiss-cpu, fairseq\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: Cython\n","    Found existing installation: Cython 0.29.30\n","    Uninstalling Cython-0.29.30:\n","      Successfully uninstalled Cython-0.29.30\n","Successfully installed Cython-0.29.6 PyYAML-6.0 antlr4-python3-runtime-4.9.3 colorama-0.4.4 dataclasses-0.6 fairseq-0.10.2 faiss-cpu-1.7.2 faiss-gpu-1.7.2 fastBPE-0.1.0 hydra-core-1.2.0 omegaconf-2.2.2 portalocker-2.4.0 sacrebleu-2.1.0 sentencepiece-0.1.96 transliterate-1.10.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{}}]},{"cell_type":"code","source":["#!git clone https://github.com/facebookresearch/LASER.git"],"metadata":{"id":"cfqn0BHSfEZx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08z07sGxfVAi","executionInfo":{"status":"ok","timestamp":1654589967379,"user_tz":-120,"elapsed":410,"user":{"displayName":"Everlyn Asiko Chimoto","userId":"04364481505979678301"}},"outputId":"9dba00b8-2473-472f-b66c-a91373f552f2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["BUCC.ipynb  LASER  Laser.ipynb\tLuhya.csv  requirements.txt  swahilisawa.csv\n"]}]},{"cell_type":"code","source":["!cd LASER; export LASER=\"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER\"; bash ./install_models.sh; bash ./install_external_tools.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_w-2EGwf82W","executionInfo":{"status":"ok","timestamp":1654502531373,"user_tz":-120,"elapsed":5571,"user":{"displayName":"Everlyn Asiko Chimoto","userId":"04364481505979678301"}},"outputId":"3121de03-701f-49b6-aa58-612256f40091"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading networks\n"," - /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.eparl21.2018-11-19.pt already downloaded\n"," - /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/eparl21.fcodes already downloaded\n"," - /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/eparl21.fvocab already downloaded\n"," - /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.93langs.2018-12-26.pt already downloaded\n"," - /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/93langs.fcodes already downloaded\n"," - /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/93langs.fvocab already downloaded\n","Installing external tools\n","\n","automatic installation of the Japanese tokenizer mecab may be tricky\n","Please install it manually from https://github.com/taku910/mecab\n","\n","The installation directory should be /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/mecab\n","\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MxPVSUgHgaGi","executionInfo":{"status":"ok","timestamp":1654502542021,"user_tz":-120,"elapsed":589,"user":{"displayName":"Everlyn Asiko Chimoto","userId":"04364481505979678301"}},"outputId":"036735a0-658f-4117-a79f-d7587187eab3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BUCC.ipynb  LASER  Laser.ipynb\tLuhya.csv  requirements.txt  swahilisawa.csv\n"]}]},{"cell_type":"code","source":["!chmod +x /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/tokenizer.perl"],"metadata":{"id":"ILzGPRWBlOl_","executionInfo":{"status":"ok","timestamp":1654545302260,"user_tz":-120,"elapsed":494,"user":{"displayName":"Everlyn Asiko Chimoto","userId":"04364481505979678301"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["!cd LASER/tasks/bucc; export LASER=\"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER\"; bash ./bucc.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_6u3IA0yhaC6","executionInfo":{"status":"ok","timestamp":1654590119675,"user_tz":-120,"elapsed":142781,"user":{"displayName":"Everlyn Asiko Chimoto","userId":"04364481505979678301"}},"outputId":"e98f4fd0-03e8-456c-ac6d-66a5fd41f2b9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Processing BUCC data in .\n"," - Encoder: loading /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.93langs.2018-12-26.pt\n"," - Tokenizer:  in language fr  \n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/tokenizer.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/remove-non-printing-char.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/normalize-punctuation.perl: Permission denied\n"," - fast BPE: processing tok\n"," - Encoder: bpe to bucc2018.fr-en.train.enc.fr\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 636, in <module>\n","    fp16=args.fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 542, in embed_sentences\n","    fp16=fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 432, in EncodeFile\n","    if len(inp_fname) > 0\n","FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpisdc2lrs/bpe'\n"," - Encoder: loading /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.93langs.2018-12-26.pt\n"," - Tokenizer:  in language en  \n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/normalize-punctuation.perl: Permission denied\n","/bin/sh: 1: /bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/remove-non-printing-char.perl: Permission denied\n","/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/tokenizer.perl: Permission denied\n"," - fast BPE: processing tok\n"," - Encoder: bpe to bucc2018.fr-en.train.enc.en\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 636, in <module>\n","    fp16=args.fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 542, in embed_sentences\n","    fp16=fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 432, in EncodeFile\n","    if len(inp_fname) > 0\n","FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpxb4n2m2x/bpe'\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.fr-en.train.txt.fr: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.fr-en.train.txt.en: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.fr-en.train.enc.fr'\n"," - Encoder: loading /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.93langs.2018-12-26.pt\n"," - Tokenizer:  in language fr  \n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/normalize-punctuation.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/tokenizer.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/remove-non-printing-char.perl: Permission denied\n"," - fast BPE: processing tok\n"," - Encoder: bpe to bucc2018.fr-en.test.enc.fr\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 636, in <module>\n","    fp16=args.fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 542, in embed_sentences\n","    fp16=fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 432, in EncodeFile\n","    if len(inp_fname) > 0\n","FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpneqk169g/bpe'\n"," - Encoder: loading /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.93langs.2018-12-26.pt\n"," - Tokenizer:  in language en  \n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/tokenizer.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/remove-non-printing-char.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/normalize-punctuation.perl: Permission denied\n"," - fast BPE: processing tok\n"," - Encoder: bpe to bucc2018.fr-en.test.enc.en\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 636, in <module>\n","    fp16=args.fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 542, in embed_sentences\n","    fp16=fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 432, in EncodeFile\n","    if len(inp_fname) > 0\n","FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpvsc00ub6/bpe'\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.fr-en.test.txt.fr: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.fr-en.test.txt.en: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.fr-en.test.enc.fr'\n","usage: bucc.py [-h] [--encoding ENCODING] --src-lang SRC_LANG --trg-lang\n","               TRG_LANG --bucc-texts BUCC_TEXTS --bucc-ids BUCC_IDS\n","               --candidates CANDIDATES [--gold GOLD] [--threshold THRESHOLD]\n","               [--output OUTPUT] [--verbose]\n","bucc.py: error: argument --threshold: expected one argument\n"," - Encoder: loading /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.93langs.2018-12-26.pt\n"," - Tokenizer:  in language de  \n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/tokenizer.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/normalize-punctuation.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/remove-non-printing-char.perl: Permission denied\n"," - fast BPE: processing tok\n"," - Encoder: bpe to bucc2018.de-en.train.enc.de\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 636, in <module>\n","    fp16=args.fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 542, in embed_sentences\n","    fp16=fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 432, in EncodeFile\n","    if len(inp_fname) > 0\n","FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmptk8olg6q/bpe'\n"," - Encoder: loading /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.93langs.2018-12-26.pt\n"," - Tokenizer:  in language en  \n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/tokenizer.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/remove-non-printing-char.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/normalize-punctuation.perl: Permission denied\n"," - fast BPE: processing tok\n"," - Encoder: bpe to bucc2018.de-en.train.enc.en\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 636, in <module>\n","    fp16=args.fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 542, in embed_sentences\n","    fp16=fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 432, in EncodeFile\n","    if len(inp_fname) > 0\n","FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpemkyus0t/bpe'\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.de-en.train.txt.de: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.de-en.train.txt.en: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.de-en.train.enc.de'\n"," - Encoder: loading /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.93langs.2018-12-26.pt\n"," - Tokenizer:  in language de  \n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/remove-non-printing-char.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/normalize-punctuation.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/tokenizer.perl: Permission denied\n"," - fast BPE: processing tok\n"," - Encoder: bpe to bucc2018.de-en.test.enc.de\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 636, in <module>\n","    fp16=args.fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 542, in embed_sentences\n","    fp16=fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 432, in EncodeFile\n","    if len(inp_fname) > 0\n","FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmp1rge207c/bpe'\n"," - Encoder: loading /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.93langs.2018-12-26.pt\n"," - Tokenizer:  in language en  \n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/remove-non-printing-char.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/normalize-punctuation.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/tokenizer.perl: Permission denied\n"," - fast BPE: processing tok\n"," - Encoder: bpe to bucc2018.de-en.test.enc.en\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 636, in <module>\n","    fp16=args.fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 542, in embed_sentences\n","    fp16=fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 432, in EncodeFile\n","    if len(inp_fname) > 0\n","FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpt6flm2y6/bpe'\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.de-en.test.txt.de: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.de-en.test.txt.en: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.de-en.test.enc.de'\n","usage: bucc.py [-h] [--encoding ENCODING] --src-lang SRC_LANG --trg-lang\n","               TRG_LANG --bucc-texts BUCC_TEXTS --bucc-ids BUCC_IDS\n","               --candidates CANDIDATES [--gold GOLD] [--threshold THRESHOLD]\n","               [--output OUTPUT] [--verbose]\n","bucc.py: error: argument --threshold: expected one argument\n"," - Encoder: loading /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.93langs.2018-12-26.pt\n"," - Tokenizer:  in language ru  \n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/normalize-punctuation.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/tokenizer.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/remove-non-printing-char.perl: Permission denied\n"," - fast BPE: processing tok\n"," - Encoder: bpe to bucc2018.ru-en.train.enc.ru\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 636, in <module>\n","    fp16=args.fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 542, in embed_sentences\n","    fp16=fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 432, in EncodeFile\n","    if len(inp_fname) > 0\n","FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpf75rokb5/bpe'\n"," - Encoder: loading /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.93langs.2018-12-26.pt\n"," - Tokenizer:  in language en  \n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/tokenizer.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/normalize-punctuation.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/remove-non-printing-char.perl: Permission denied\n"," - fast BPE: processing tok\n"," - Encoder: bpe to bucc2018.ru-en.train.enc.en\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 636, in <module>\n","    fp16=args.fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 542, in embed_sentences\n","    fp16=fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 432, in EncodeFile\n","    if len(inp_fname) > 0\n","FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpr9f4voqh/bpe'\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.ru-en.train.txt.ru: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.ru-en.train.txt.en: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.ru-en.train.enc.ru'\n"," - Encoder: loading /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.93langs.2018-12-26.pt\n"," - Tokenizer:  in language ru  \n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/tokenizer.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/remove-non-printing-char.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/normalize-punctuation.perl: Permission denied\n"," - fast BPE: processing tok\n"," - Encoder: bpe to bucc2018.ru-en.test.enc.ru\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 636, in <module>\n","    fp16=args.fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 542, in embed_sentences\n","    fp16=fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 432, in EncodeFile\n","    if len(inp_fname) > 0\n","FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpccfvl7sh/bpe'\n"," - Encoder: loading /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.93langs.2018-12-26.pt\n"," - Tokenizer:  in language en  \n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/remove-non-printing-char.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/normalize-punctuation.perl: Permission denied/bin/sh: 1: \n","/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/tokenizer.perl: Permission denied\n"," - fast BPE: processing tok\n"," - Encoder: bpe to bucc2018.ru-en.test.enc.en\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 636, in <module>\n","    fp16=args.fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 542, in embed_sentences\n","    fp16=fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 432, in EncodeFile\n","    if len(inp_fname) > 0\n","FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpg2hhosrf/bpe'\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.ru-en.test.txt.ru: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.ru-en.test.txt.en: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.ru-en.test.enc.ru'\n","usage: bucc.py [-h] [--encoding ENCODING] --src-lang SRC_LANG --trg-lang\n","               TRG_LANG --bucc-texts BUCC_TEXTS --bucc-ids BUCC_IDS\n","               --candidates CANDIDATES [--gold GOLD] [--threshold THRESHOLD]\n","               [--output OUTPUT] [--verbose]\n","bucc.py: error: argument --threshold: expected one argument\n"," - Encoder: loading /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.93langs.2018-12-26.pt\n"," - Tokenizer:  in language zh  \n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/remove-non-printing-char.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/normalize-punctuation.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/tokenizer.perl: Permission denied\n","Building prefix dict from the default dictionary ...\n","Dumping model to file cache /tmp/jieba.cache\n","Loading model cost 0.760 seconds.\n","Prefix dict has been built successfully.\n"," - fast BPE: processing tok\n"," - Encoder: bpe to bucc2018.zh-en.train.enc.zh\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 636, in <module>\n","    fp16=args.fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 542, in embed_sentences\n","    fp16=fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 432, in EncodeFile\n","    if len(inp_fname) > 0\n","FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpyf1xf1nq/bpe'\n"," - Encoder: loading /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.93langs.2018-12-26.pt\n"," - Tokenizer:  in language en  \n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/remove-non-printing-char.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/tokenizer.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/normalize-punctuation.perl: Permission denied\n"," - fast BPE: processing tok\n"," - Encoder: bpe to bucc2018.zh-en.train.enc.en\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 636, in <module>\n","    fp16=args.fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 542, in embed_sentences\n","    fp16=fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 432, in EncodeFile\n","    if len(inp_fname) > 0\n","FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmp00lnekl1/bpe'\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.zh-en.train.txt.zh: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.zh-en.train.txt.en: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.zh-en.train.enc.zh'\n"," - Encoder: loading /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.93langs.2018-12-26.pt\n"," - Tokenizer:  in language zh  \n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/remove-non-printing-char.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/normalize-punctuation.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/tokenizer.perl: Permission denied\n","Building prefix dict from the default dictionary ...\n","Loading model from cache /tmp/jieba.cache\n","Loading model cost 0.667 seconds.\n","Prefix dict has been built successfully.\n"," - fast BPE: processing tok\n"," - Encoder: bpe to bucc2018.zh-en.test.enc.zh\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 636, in <module>\n","    fp16=args.fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 542, in embed_sentences\n","    fp16=fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 432, in EncodeFile\n","    if len(inp_fname) > 0\n","FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmp7hkg9230/bpe'\n"," - Encoder: loading /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/models/bilstm.93langs.2018-12-26.pt\n"," - Tokenizer:  in language en  \n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/tokenizer.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/remove-non-printing-char.perl: Permission denied\n","/bin/sh: 1: /content/gdrive/Shareddrives/LASER_on_Luhya/LASER/tools-external/moses-tokenizer/tokenizer/normalize-punctuation.perl: Permission denied\n"," - fast BPE: processing tok\n"," - Encoder: bpe to bucc2018.zh-en.test.enc.en\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 636, in <module>\n","    fp16=args.fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 542, in embed_sentences\n","    fp16=fp16,\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 432, in EncodeFile\n","    if len(inp_fname) > 0\n","FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpvmmcpvvy/bpe'\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.zh-en.test.txt.zh: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.zh-en.test.txt.en: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.zh-en.test.enc.zh'\n","usage: bucc.py [-h] [--encoding ENCODING] --src-lang SRC_LANG --trg-lang\n","               TRG_LANG --bucc-texts BUCC_TEXTS --bucc-ids BUCC_IDS\n","               --candidates CANDIDATES [--gold GOLD] [--threshold THRESHOLD]\n","               [--output OUTPUT] [--verbose]\n","bucc.py: error: argument --threshold: expected one argument\n","Extracting bitexts for fr-de\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.fr-en.train.txt.fr: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.de-en.train.txt.de: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.fr-en.train.enc.fr'\n","Extracting bitexts for fr-ru\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.fr-en.train.txt.fr: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.ru-en.train.txt.ru: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.fr-en.train.enc.fr'\n","Extracting bitexts for fr-zh\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.fr-en.train.txt.fr: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.zh-en.train.txt.zh: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.fr-en.train.enc.fr'\n","Extracting bitexts for de-fr\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.de-en.train.txt.de: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.fr-en.train.txt.fr: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.de-en.train.enc.de'\n","Extracting bitexts for de-ru\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.de-en.train.txt.de: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.ru-en.train.txt.ru: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.de-en.train.enc.de'\n","Extracting bitexts for de-zh\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.de-en.train.txt.de: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.zh-en.train.txt.zh: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.de-en.train.enc.de'\n","Extracting bitexts for ru-fr\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.ru-en.train.txt.ru: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.fr-en.train.txt.fr: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.ru-en.train.enc.ru'\n","Extracting bitexts for ru-de\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.ru-en.train.txt.ru: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.de-en.train.txt.de: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.ru-en.train.enc.ru'\n","Extracting bitexts for ru-zh\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.ru-en.train.txt.ru: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.zh-en.train.txt.zh: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.ru-en.train.enc.ru'\n","Extracting bitexts for zh-fr\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.zh-en.train.txt.zh: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.fr-en.train.txt.fr: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.zh-en.train.enc.zh'\n","Extracting bitexts for zh-de\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.zh-en.train.txt.zh: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.de-en.train.txt.de: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.zh-en.train.enc.zh'\n","Extracting bitexts for zh-ru\n","LASER: tool to search, score or mine bitexts\n"," - knn will run on all available GPUs (recommended)\n"," - loading texts ./embed/bucc2018.zh-en.train.txt.zh: 0 lines, 0 unique\n"," - loading texts ./embed/bucc2018.ru-en.train.txt.ru: 0 lines, 0 unique\n","Traceback (most recent call last):\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/mine_bitexts.py\", line 214, in <module>\n","    x = EmbedLoad(args.src_embeddings, args.dim, verbose=args.verbose)\n","  File \"/content/gdrive/Shareddrives/LASER_on_Luhya/LASER/source/embed.py\", line 447, in EmbedLoad\n","    x = np.fromfile(fname, dtype=np.float32, count=-1)\n","FileNotFoundError: [Errno 2] No such file or directory: './embed/bucc2018.zh-en.train.enc.zh'\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"nPggtP5jxmP3"},"execution_count":null,"outputs":[]}]}